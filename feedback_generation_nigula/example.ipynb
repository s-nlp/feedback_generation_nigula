{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db4b6ab-7d9e-4d42-81b3-34f70699081e",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8886c8-7f38-4a78-806a-0172304d12ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from feedback_generation_nigula.generator import FeedbackGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65076ec-2bff-4c31-ba16-eb65f3b02039",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = FeedbackGenerator(cuda_index = 0) # pass cuda_index=False if you want to use the model in CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfeb9d27-1bdd-4aba-bd4f-5056eb9823da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The smoke flow my face .\"\n",
    "span = (10,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c5ae6d-cc35-48fe-9e97-45c8b20ebd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When the <verb> <<flow>> is used as an <intransitive verb> to express'' to move in a stream'', a <preposition> needs to be placed to indicate the direction\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.get_feedback([text], [span]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87912d31-47d7-42c4-ab68-156d80ea7054",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a0a582-5472-429c-bd1a-851014464efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from feedback_generation_nigula.augment import  get_smart_truncated_string, Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebfa734-b808-4cda-ae44-33f68dfde65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'They can help their father or mother about money that we must use in the university too .'\n",
    "offset = [37, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a139b3-0e5e-4a7c-b97a-c2bf3aec1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_text = get_smart_truncated_string(text, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b880f4df-da9c-4c49-be8c-641434efd84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they can help their father or mother about money'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6fe6610-9ea7-4da0-b613-546fd62d95a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342978cdf4b94e859fcdb07d35d3c21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a1d171867f48349dea13e89315faa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb486cc172949a4a3fb69b452b1e14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f2da3255c54fc7b7df22f01343dc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd35f44d83314d61ba0c932305cf0b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4c283904054f979fb870ace1e48530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babakov/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:145: UserWarning: \n",
      "NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "aug = Augmenter(cuda_index = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c793f2-9977-452d-8e21-6bc9b9696fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'they can help their father or mother about money or they can take courses and become a lawyer, engineer, businessperson etc. but on the basis of religion you will be given a different kind of path. There is no one god or one way of life. All you will have to do as it is the society they live in.\\n\\nSo if someone of your religion is a terrorist and wants to kill you as well as your family, the best thing to do is to tell them to leave'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug.augment(truncated_text, is_text_truncated = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d528e233-7612-4722-a5f0-367e51f5c0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'they can help their father or mother about money.\"\\n\\n\"And the others too?\" I asked.\\n\\n\"My mother does,\" he said. \"And my brother, my sister is not well. And some\\npeople at court, too. Many people. In my house the people are not well. And\\nthat\\'s why I have been so silent.\"\\n\\n\"You are a kind man,\" I said. And he was a kind man himself. But I was not\\nsure'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug.augment(text, is_text_truncated = False, err_word_offset = offset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
